# -*- coding: utf-8 -*-
"""Cloud security-zero trust -dataset 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14p_J8T2cN51h_qRlhCE8_WPo7eL6Cd-p
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("chethuhn/network-intrusion-dataset")

print("Path to dataset files:", path)

# prompt: code to list path to all files in above directory

import os
for root, dirs, files in os.walk(path):
    for file in files:
        print(os.path.join(root, file))

"""#**Data** **Loading**"""

import pandas as pd

df1=pd.read_csv('/root/.cache/kagglehub/datasets/chethuhn/network-intrusion-dataset/versions/1/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')

df1.head()

df1.shape

df1.isnull().sum()

df1.dtypes

cat_col = []
for col in df1.columns:
  if df1[col].dtype == 'object':
    cat_col.append(col)
cat_col

df1[' Label'].value_counts()

"""#**Visualisation**"""

#  label distribution graph

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df1 is your DataFrame and ' Label' is the column with labels
plt.figure(figsize=(12, 6))
sns.countplot(x=' Label', data=df1)
plt.title('Label Distribution')
plt.xlabel('Label')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

for col in df1.columns:
    # Skip non-numeric columns
    if df1[col].dtype not in ['float64', 'int64']:
        continue

    # Plot distribution
    sns.displot(
        data=df1, x=col, kde=True, color='skyblue', bins=30, aspect=1.5
    )

    # Add customizations
    plt.title(f'Distribution of {col}', fontsize=14)
    plt.xlabel(col, fontsize=12)
    plt.ylabel('Frequency/Count', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

# Display all column names
print(df1.columns.tolist())

from sklearn.preprocessing import LabelEncoder
lab_enc = LabelEncoder()
for col in cat_col:
  df1[col] = lab_enc.fit_transform(df1[col])

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation matrix
correlation_matrix = df1.corr()



plt.figure(figsize=(30, 25))


sns.heatmap(
    correlation_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    cbar_kws={"shrink": 0.8},
    linewidths=0.5
)

# Add title and labels
plt.title("Improved Correlation Heatmap of Features", fontsize=25, pad=20)
plt.xticks(fontsize=12, rotation=45, ha='right')
plt.yticks(fontsize=12)
plt.tight_layout()

# Show the plot
plt.show()

"""feature extraction"""

import pandas as pd



# Identify features with correlation > 0.9
threshold = 0.9
correlated_features = set()

for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > threshold:
            col_name = correlation_matrix.columns[i]
            correlated_features.add(col_name)

# Drop highly correlated features
reduced_df = df1.drop(columns=correlated_features)

print(f"Number of features dropped: {len(correlated_features)}")
print(f"Remaining features: {reduced_df.columns.tolist()}")

import numpy as np
import pandas as pd

# Replace positive infinity and negative infinity with NaN
reduced_df.replace([np.inf, -np.inf], np.nan, inplace=True)
df1.replace([np.inf, -np.inf], np.nan, inplace=True)
#  Replace NaNs with the column mean (or median)
reduced_df.fillna(reduced_df.mean(), inplace=True)
df1.fillna(reduced_df.mean(), inplace=True)
# Check the dataset for any remaining infinity or NaN values
print(df1.isin([np.inf, -np.inf]).sum())
print('--------------------------')
print(reduced_df.isin([np.inf, -np.inf]).sum())  # Should return 0 for all columns

"""#**Validating feature selection**

before feature extraction results
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split




X1 = df1.drop(' Label', axis=1)
y1 = df1[' Label']

# Scale the features using MinMaxScaler
scaler1 = MinMaxScaler()
X_scaled1 = scaler1.fit_transform(X1)

# Standardize the scaled features using StandardScaler
standardizer1 = StandardScaler()
X_standardized1 = standardizer1.fit_transform(X_scaled1)

# Create a new DataFrame with standardized features
X_processed1 = pd.DataFrame(X_standardized1, columns=X1.columns)

# Concatenate the processed features with the target variable
processed_df = pd.concat([X_processed1, y1], axis=1)


X_train1, X_test1, y_train1, y_test1 = train_test_split(
    X_processed1, y1, test_size=0.2, random_state=42
)

print(f"Shape of X_train: {X_train1.shape}")
print(f"Shape of X_test: {X_test1.shape}")
print(f"Shape of y_train: {y_train1.shape}")
print(f"Shape of y_test: {y_test1.shape}")

#  random forest

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Initialize and train the RandomForestClassifier
rf_classifier1 = RandomForestClassifier(n_estimators=100, random_state=42) # You can adjust n_estimators
rf_classifier1.fit(X_train1, y_train1)

# Make predictions on the test set
y_pred1 = rf_classifier1.predict(X_test1)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test1, y_pred1))
print("\nClassification Report:\n", classification_report(y_test1, y_pred1))

# Confusion Matrix
cm = confusion_matrix(y_test1, y_pred1)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""after feature extraction results"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler



# Separate features (X) and target variable (y)
X = reduced_df.drop(' Label', axis=1)
y = reduced_df[' Label']

# Scale the features using MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Standardize the scaled features using StandardScaler
standardizer = StandardScaler()
X_standardized = standardizer.fit_transform(X_scaled)

# Create a new DataFrame with standardized features
X_processed = pd.DataFrame(X_standardized, columns=X.columns)

# Concatenate the processed features with the target variable
processed_df = pd.concat([X_processed, y], axis=1)


from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.2, random_state=42
)

print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of y_test: {y_test.shape}")

# random forest

# Initialize and train the RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42) # You can adjust n_estimators
rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

#Classification Report
class_report = classification_report(y_test, y_pred, output_dict=True)
print(f"Precision: {class_report['weighted avg']['precision']:.4f}")
print(f"Recall: {class_report['weighted avg']['recall']:.4f}")
print(f"F1-score: {class_report['weighted avg']['f1-score']:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""resulte are almost coming same so we can proceed with reduced features

#**Model Training**
"""

#  decision tree classifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize and train the DecisionTreeClassifier
dt_classifier = DecisionTreeClassifier(
    random_state=42,
    max_depth=None,
    min_samples_split=20,
    min_samples_leaf=10,
    max_features=1,
    criterion='gini'
)
dt_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#  Knn classifier

from sklearn.neighbors import KNeighborsClassifier

# Initialize and train the KNeighborsClassifier
knn_classifier = KNeighborsClassifier(
    n_neighbors=3,
    weights='uniform',
    algorithm='auto',
)
knn_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = knn_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Logistic regression

from sklearn.linear_model import LogisticRegression

# Initialize and train the Logistic Regression model
logreg_classifier = LogisticRegression(random_state=42, max_iter=1000) # Increased max_iter
logreg_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = logreg_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#  XGboost ix

from xgboost import XGBClassifier

# Initialize and train the XGBoost classifier
xgb_classifier = XGBClassifier(
    random_state=42,
    use_label_encoder=False,
    eval_metric='logloss',
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    gamma=0.1
)
xgb_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = xgb_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#  MLP

from sklearn.neural_network import MLPClassifier

# Initialize and train the MLP Classifier
mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50),
                                 max_iter=500,
                                 activation='relu',
                                 solver='adam',
                                 random_state=42,
                                 early_stopping=True,
                                 verbose=True)

mlp_classifier.fit(X_train, y_train)


# Make predictions on the test set
y_pred = mlp_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#  random forest


# Initialize and train the RandomForestClassifier
rf_classifier = RandomForestClassifier(
    n_estimators=50,
    random_state=42,
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=5,
    max_features='sqrt',
    bootstrap=False
)

rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

precision = precision_score(y_test, y_pred, average='weighted')
print(f"Precision: {precision:.4f}")

recall = recall_score(y_test, y_pred, average='weighted')
print(f"Recall: {recall:.4f}")

f1 = f1_score(y_test, y_pred, average='weighted')
print(f"F1-score: {f1:.4f}")

# Classification Report
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#  Naive Bayes
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize and train the Gaussian Naive Bayes classifier
nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = nb_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

precision = precision_score(y_test, y_pred, average='weighted')
print(f"Precision: {precision:.4f}")

recall = recall_score(y_test, y_pred, average='weighted')
print(f"Recall: {recall:.4f}")

f1 = f1_score(y_test, y_pred, average='weighted')
print(f"F1-score: {f1:.4f}")

# Classification Report
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""saving datset and model

"""

reduced_df.to_csv('processed_dataset.csv', index=False)

from google.colab import files
files.download('processed_dataset.csv')

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier


X3 = reduced_df.drop(columns=[' Label'])
y3 = reduced_df[' Label']

# Train a Random Forest model
model = RandomForestClassifier(random_state=42)
model.fit(X3, y3)

# Get feature importances
importances = model.feature_importances_
feature_names = X3.columns

# Create a dataframe for visualization
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importances
plt.figure(figsize=(20, 15))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.gca().invert_yaxis()  # Invert y-axis for descending order
plt.title('Feature Importance')
plt.xlabel('Importance')
plt.show()

# Select the top 10 features
top_10_features = importance_df.head(10)['Feature']

# Create a new dataframe with only the top 10 features
new_df = reduced_df[top_10_features]
new_df[' Label'] = y3  # Add target back to the new dataframe if needed

print(new_df.head())

new_df.to_csv('CICDS_2017_top10_dataset.csv', index=False)

from google.colab import files
files.download('CICDS_2017_top10_dataset.csv')

print(new_df.columns.tolist())

# prompt: train random forest on new_df and give result metrics

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns


# Separate features and target variable
X = new_df.drop(' Label', axis=1)
y = new_df[' Label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a Random Forest Classifier
rf_classifier3 = RandomForestClassifier(random_state=42)
rf_classifier3.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier3.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

precision = precision_score(y_test, y_pred, average='weighted')
print(f"Precision: {precision:.4f}")

recall = recall_score(y_test, y_pred, average='weighted')
print(f"Recall: {recall:.4f}")

f1 = f1_score(y_test, y_pred, average='weighted')
print(f"F1-score: {f1:.4f}")

# Classification Report
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Saving the above model for streamlit

"""

import pickle
filename='zta_finalized_model.sav'
pickle.dump(rf_classifier3,open(filename,'wb'))

